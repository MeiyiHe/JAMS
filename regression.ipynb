{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"/Users/shutinggu/Desktop/1001-project/renttherunway_final_data.json\"\n",
    "df = pd.read_json(file,lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- map cups to numerical value ---\n",
      "{'cups': {'a': 1, 'b': 2, 'c': 3, 'd': 4, 'f': 5, 'g': 6, 'h': 7, 'i': 8, 'j': 9}}\n"
     ]
    }
   ],
   "source": [
    "# transfer bust size into bust size and cups\n",
    "df=df.dropna()\n",
    "df['cups'] = df['bust size'].str.extract(r'([a-z])')\n",
    "labels = df['cups'].astype('category').cat.categories.tolist()\n",
    "replace_map = {'cups' : {k: v for k,v in zip(labels,list(range(1,len(labels)+1)))}}\n",
    "print('--- map cups to numerical value ---')\n",
    "print(replace_map)\n",
    "df.replace(replace_map, inplace=True)\n",
    "df['bust size'] = df['bust size'].str.extract('(\\d+)').astype(int)\n",
    "# remove lbs after 'weight'\n",
    "df['weight'] = df['weight'].str.extract('(\\d+)').astype(int)\n",
    "# parse height to usable numerical format\n",
    "def parse_height(ht):\n",
    "    ht_ = ht.split(\"' \")\n",
    "    ft_ = float(ht_[0])\n",
    "    in_ = float(ht_[1].replace(\"\\\"\",\"\"))\n",
    "    return (12*ft_) + in_\n",
    "df['height'] = df['height'].apply(lambda x:parse_height(x))\n",
    "# change 'party: cocktail' in 'rented for' to 'others'\n",
    "df.loc[df['rented for'] == 'party: cocktail', df.columns == 'rented for'] = 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(columns=['user_id', 'item_id','review_date','review_summary','review_text','fit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['romper', 'gown', 'dress', 'sheath', 'leggings', 'sweater',\n",
       "       'jacket', 'shirtdress', 'jumpsuit', 'shift', 'top', 'shirt',\n",
       "       'mini', 'skirt', 'maxi', 'pants', 'suit', 'coat', 'blouse',\n",
       "       'trench', 'cape', 'bomber', 'blazer', 'vest', 'duster', 'ballgown',\n",
       "       'tank', 'poncho', 'frock', 'tunic', 'cardigan', 'down', 'culottes',\n",
       "       'midi', 'legging', 'print', 'pant', 'knit', 'culotte',\n",
       "       'sweatshirt', 'peacoat', 'trouser', 'kaftan', 'overalls', 'jogger',\n",
       "       'tee', 'combo', 'henley', 'blouson', 'pullover', 'turtleneck',\n",
       "       'trousers', 'overcoat', 'hoodie', 't-shirt', 'caftan', 'tight',\n",
       "       'kimono', 'cami', 'for', 'crewneck', 'skirts', 'parka',\n",
       "       'buttondown', 'skort', 'sweatershirt', 'jeans', 'sweatpants'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['category'].isin(['sweater','shirt','blouse','vest','tank','tunic','print','sweatshirt',\n",
    "                            'tee','blouson','turtleneck','hoodie','t-shirt','cami','crewneck',\n",
    "                            'buttondown','sweatershirt'\n",
    "                           ]),df.columns=='category']='tops'\n",
    "df.loc[df['category'].isin(['pants','down','culottes','pant','trouser','culotte','jogger',\n",
    "                            'trousers','jeans', 'sweatpants'\n",
    "                           ]),df.columns=='category']='bottoms'\n",
    "df.loc[df['category'].isin(['ballgown']),df.columns=='category']='gown'\n",
    "df.loc[df['category'].isin(['leggings','legging']),df.columns=='category']='active'\n",
    "df.loc[df['category'].isin(['jacket','trench','cape','bomber','blazer','duster','poncho',\n",
    "                            'cardigan','peacoat','pullover','overcoat','parka'\n",
    "                           ]),df.columns=='category']='coat'\n",
    "df.loc[df['category'].isin(['mini','midi','skirts']),df.columns=='category']='skirt'\n",
    "df.loc[df['category'].isin(['jumpsuit']),df.columns=='category']='romper'\n",
    "df.loc[df['category'].isin(['sheath','shift','maxi','shirtdress','frock','kaftan','caftan'\n",
    "                           ]),df.columns=='category']='dress'\n",
    "df.loc[df['category'].isin(['overalls','combo','henley','tight','kimono','for','skort']),df.columns=='category']='other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 146381 entries, 0 to 192543\n",
      "Data columns (total 10 columns):\n",
      "age           146381 non-null float64\n",
      "body type     146381 non-null object\n",
      "bust size     146381 non-null int64\n",
      "category      146381 non-null object\n",
      "height        146381 non-null float64\n",
      "rating        146381 non-null float64\n",
      "rented for    146381 non-null object\n",
      "size          146381 non-null int64\n",
      "weight        146381 non-null int64\n",
      "cups          146381 non-null int64\n",
      "dtypes: float64(3), int64(4), object(3)\n",
      "memory usage: 12.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "df= pd.get_dummies(df, columns=['body type','category','rented for'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop(columns=['rating'],axis=1)\n",
    "y=df['rating']\n",
    "x_train, x_test,y_train,y_test = train_test_split(x,y, test_size=0.33)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Train MSE: 2.0381677476356383\n",
      "Linear Regression Test MSE: 2.0394645238896953\n"
     ]
    }
   ],
   "source": [
    "#Linear Regression\n",
    "lg=LinearRegression(normalize=True).fit(x_train,y_train)\n",
    "lg_train_pred=lg.predict(x_train)\n",
    "lg_train_mse=mean_squared_error(y_train, lg_train_pred)\n",
    "print('Linear Regression Train MSE:',lg_train_mse)\n",
    "lg_test_pred=lg.predict(x_test)\n",
    "lg_test_mse=mean_squared_error(y_test, lg_test_pred)\n",
    "print('Linear Regression Test MSE:',lg_test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Regressor Train MSE: 1.988644428707625\n",
      "Decision Tree Regressor Test MSE: 2.0671111922425105\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree Regressor\n",
    "dt=DecisionTreeRegressor(min_samples_split=10,min_samples_leaf=10, max_depth=10).fit(x_train,y_train)\n",
    "dt_train_pred=dt.predict(x_train)\n",
    "dt_train_mse=mean_squared_error(y_train, dt_train_pred)\n",
    "print('Decision Tree Regressor Train MSE:',dt_train_mse)\n",
    "dt_test_pred=dt.predict(x_test)\n",
    "dt_test_mse=mean_squared_error(y_test, dt_test_pred)\n",
    "print('Decision Tree Regressor Test MSE:',dt_test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor Train MSE: 1.9684521356665972\n",
      "Random Forest Regressor Test MSE: 2.032091826358045\n"
     ]
    }
   ],
   "source": [
    "#Random Forest regressor\n",
    "rm=RandomForestRegressor(max_depth=10,n_estimators=100,min_samples_split=10,min_samples_leaf=10).fit(x_train,y_train)\n",
    "rm_train_pred=rm.predict(x_train)\n",
    "rm_train_mse=mean_squared_error(y_train, rm_train_pred)\n",
    "print('Random Forest Regressor Train MSE:',rm_train_mse)\n",
    "rm_test_pred=rm.predict(x_test)\n",
    "rm_test_mse=mean_squared_error(y_test, rm_test_pred)\n",
    "print('Random Forest Regressor Test MSE:',rm_test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient Boosting Regressor\n",
    "gb=GradientBoostingRegressor(loss='ls', learning_rate=0.001, n_estimators=100, min_samples_split=10, max_depth=10).fit(x_train,y_train)\n",
    "gb_train_pred=gb.predict(x_train)\n",
    "gb_train_mse=mean_squared_error(y_train, gb_train_pred)\n",
    "print('Gradient Boosting Regressor Train MSE:',gb_train_mse)\n",
    "gb_test_pred=gb.predict(x_test)\n",
    "gb_test_mse=mean_squared_error(y_test, gb_test_pred)\n",
    "print('Gradient Boosting Regressor Test MSE:',gb_test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
