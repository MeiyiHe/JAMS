{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"../data/renttherunway_final_data.json\"\n",
    "df = pd.read_json(file, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- map rented for to numerical value ---\n",
      "{'rented for': {'date': 1, 'everyday': 2, 'formal affair': 3, 'other': 4, 'party': 5, 'vacation': 6}}\n",
      "--- map cups to numerical value ---\n",
      "{'cups': {'a': 1, 'b': 2, 'c': 3, 'd': 4, 'f': 5, 'g': 6, 'h': 7, 'i': 8, 'j': 9}}\n"
     ]
    }
   ],
   "source": [
    "# transfer bust size into bust size and cups\n",
    "df=df.dropna()\n",
    "\n",
    "# map 'rented for' to numerical value\n",
    "# change 'party: cocktail' in 'rented for' to 'others'\n",
    "df.loc[df['rented for'] == 'party: cocktail', df.columns == 'rented for'] = 'party'\n",
    "df.loc[df['rented for'] == 'work', df.columns == 'rented for'] = 'formal affair'\n",
    "df.loc[df['rented for'] == 'wedding', df.columns == 'rented for'] = 'formal affair'\n",
    "\n",
    "labels = df['rented for'].astype('category').cat.categories.tolist()\n",
    "replace_map = {'rented for' : {k: v for k,v in zip(labels,list(range(1,len(labels)+1)))}}\n",
    "\n",
    "print('--- map rented for to numerical value ---')\n",
    "print(replace_map)\n",
    "df.replace(replace_map, inplace=True)\n",
    "\n",
    "df['cups'] = df['bust size'].str.extract(r'([a-z])')\n",
    "labels = df['cups'].astype('category').cat.categories.tolist()\n",
    "replace_map = {'cups' : {k: v for k,v in zip(labels,list(range(1,len(labels)+1)))}}\n",
    "print('--- map cups to numerical value ---')\n",
    "print(replace_map)\n",
    "df.replace(replace_map, inplace=True)\n",
    "df['bust size'] = df['bust size'].str.extract('(\\d+)').astype(int)\n",
    "# remove lbs after 'weight'\n",
    "df['weight'] = df['weight'].str.extract('(\\d+)').astype(int)\n",
    "# parse height to usable numerical format\n",
    "def parse_height(ht):\n",
    "    ht_ = ht.split(\"' \")\n",
    "    ft_ = float(ht_[0])\n",
    "    in_ = float(ht_[1].replace(\"\\\"\",\"\"))\n",
    "    return (12*ft_) + in_\n",
    "df['height'] = df['height'].apply(lambda x:parse_height(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(columns=['user_id', 'item_id','review_date','review_summary','review_text','fit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['category'].isin(['sweater','shirt','blouse','vest','tank','tunic','print','sweatshirt',\n",
    "                            'tee','blouson','turtleneck','hoodie','t-shirt','cami','crewneck',\n",
    "                            'buttondown','sweatershirt'\n",
    "                           ]),df.columns=='category']='tops'\n",
    "df.loc[df['category'].isin(['pants','down','culottes','pant','trouser','culotte','jogger',\n",
    "                            'trousers','jeans', 'sweatpants'\n",
    "                           ]),df.columns=='category']='bottoms'\n",
    "df.loc[df['category'].isin(['ballgown']),df.columns=='category']='gown'\n",
    "df.loc[df['category'].isin(['leggings','legging']),df.columns=='category']='active'\n",
    "df.loc[df['category'].isin(['jacket','trench','cape','bomber','blazer','duster','poncho',\n",
    "                            'cardigan','peacoat','pullover','overcoat','parka'\n",
    "                           ]),df.columns=='category']='coat'\n",
    "df.loc[df['category'].isin(['mini','midi','skirts']),df.columns=='category']='skirt'\n",
    "df.loc[df['category'].isin(['jumpsuit']),df.columns=='category']='romper'\n",
    "df.loc[df['category'].isin(['sheath','shift','maxi','shirtdress','frock','kaftan','caftan'\n",
    "                           ]),df.columns=='category']='dress'\n",
    "df.loc[df['category'].isin(['overalls','combo','henley','tight','kimono','for','skort']),df.columns=='category']='other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 146381 entries, 0 to 192543\n",
      "Data columns (total 10 columns):\n",
      "age           146381 non-null float64\n",
      "body type     146381 non-null object\n",
      "bust size     146381 non-null int64\n",
      "category      146381 non-null object\n",
      "height        146381 non-null float64\n",
      "rating        146381 non-null float64\n",
      "rented for    146381 non-null int64\n",
      "size          146381 non-null int64\n",
      "weight        146381 non-null int64\n",
      "cups          146381 non-null int64\n",
      "dtypes: float64(3), int64(5), object(2)\n",
      "memory usage: 12.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "df= pd.get_dummies(df, columns=['body type','category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                            float64\n",
       "bust size                        int64\n",
       "height                         float64\n",
       "rating                         float64\n",
       "rented for                       int64\n",
       "size                             int64\n",
       "weight                           int64\n",
       "cups                             int64\n",
       "body type_apple                  uint8\n",
       "body type_athletic               uint8\n",
       "body type_full bust              uint8\n",
       "body type_hourglass              uint8\n",
       "body type_pear                   uint8\n",
       "body type_petite                 uint8\n",
       "body type_straight & narrow      uint8\n",
       "category_active                  uint8\n",
       "category_bottoms                 uint8\n",
       "category_coat                    uint8\n",
       "category_dress                   uint8\n",
       "category_gown                    uint8\n",
       "category_knit                    uint8\n",
       "category_other                   uint8\n",
       "category_romper                  uint8\n",
       "category_skirt                   uint8\n",
       "category_suit                    uint8\n",
       "category_top                     uint8\n",
       "category_tops                    uint8\n",
       "dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6\n",
       "1    4\n",
       "3    3\n",
       "4    3\n",
       "5    1\n",
       "Name: rented for, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rented for'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['rented for'], axis=1)\n",
    "y = df['rented for']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149201    3\n",
       "2482      3\n",
       "85833     3\n",
       "8413      3\n",
       "82576     5\n",
       "Name: rented for, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6142442008666836\n",
      "0.6144371299631516\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression \n",
    "lg = LogisticRegression(multi_class='ovr').fit(X_train, y_train)\n",
    "pred_train = lg.predict(X_train)\n",
    "pred_test = lg.predict(X_test)\n",
    "print(accuracy_score(y_train, pred_train))\n",
    "print(accuracy_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current c value 0.01\n",
      "0.6129696660718837\n",
      "0.6134227632178197\n",
      "current c value 0.1\n",
      "0.6141932194748917\n",
      "0.6144785326874508\n",
      "current c value 1\n",
      "0.6142442008666836\n",
      "0.6144371299631516\n",
      "current c value 5\n",
      "0.6141116492480244\n",
      "0.6144785326874508\n",
      "current c value 10\n",
      "0.6141932194748917\n",
      "0.6144785326874508\n"
     ]
    }
   ],
   "source": [
    "C_value = [0.01, 0.1, 1, 5, 10]\n",
    "for c in C_value:\n",
    "    lg = LogisticRegression(multi_class='ovr', C=c, random_state=42).fit(X_train, y_train)\n",
    "    pred_train = lg.predict(X_train)\n",
    "    pred_test = lg.predict(X_test)\n",
    "    print('current c value {}'.format(c))\n",
    "    print(accuracy_score(y_train, pred_train))\n",
    "    print(accuracy_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current depth 1\n",
      "0.5830028039765486\n",
      "0.5809630273672007\n",
      "current depth 5\n",
      "0.6137037981136885\n",
      "0.6139609986337101\n",
      "current depth 10\n",
      "0.621534539892939\n",
      "0.6118701610565975\n",
      "current depth 15\n",
      "0.6626459342340046\n",
      "0.5961371258228791\n",
      "current depth 20\n",
      "0.748580168238593\n",
      "0.5676934542292883\n",
      "current depth 30\n",
      "0.9067550344124394\n",
      "0.511344346457997\n"
     ]
    }
   ],
   "source": [
    "depth = [1, 5, 10, 15, 20, 30]\n",
    "# Decision Tree\n",
    "for d in depth:\n",
    "    dt = DecisionTreeClassifier(random_state=42, max_depth=d).fit(X_train, y_train)\n",
    "    pred_train = dt.predict(X_train)\n",
    "    pred_test = dt.predict(X_test)\n",
    "    print('current depth {}'.format(d))\n",
    "    print(accuracy_score(y_train, pred_train))\n",
    "    print(accuracy_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current depth 1\n",
      "0.5830028039765486\n",
      "0.5809630273672007\n",
      "current depth 5\n",
      "0.6053836349732348\n",
      "0.6026580549000125\n",
      "current depth 10\n",
      "0.6165995411674738\n",
      "0.6120564733159441\n",
      "current depth 15\n",
      "0.6509711955136375\n",
      "0.6148097544818449\n",
      "current depth 20\n",
      "0.7316543461636502\n",
      "0.6072744586593798\n",
      "current depth 30\n",
      "0.9016059138414478\n",
      "0.5820601995611311\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classification\n",
    "depth = [1, 5, 10, 15, 20, 30]\n",
    "for d in depth:\n",
    "    rf = RandomForestClassifier(random_state=42, max_depth=d).fit(X_train, y_train)\n",
    "    pred_train = rf.predict(X_train)\n",
    "    pred_test = rf.predict(X_test)\n",
    "    print('current depth {}'.format(d))\n",
    "    print(accuracy_score(y_train, pred_train))\n",
    "    print(accuracy_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current depth 1\n",
      "0.6135202651032373\n",
      "0.6135262700285679\n",
      "current depth 5\n",
      "0.6253479479989804\n",
      "0.6163623566430672\n",
      "current depth 10\n",
      "0.7307366811113943\n",
      "0.6141266095309071\n",
      "current depth 15\n",
      "0.9236298750955901\n",
      "0.5893263776756511\n",
      "current depth 20\n",
      "0.9399643130257456\n",
      "0.5782925516498986\n",
      "current depth 30\n",
      "0.9399643130257456\n",
      "0.5694737713741564\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Classification\n",
    "depth = [1, 5, 10, 15, 20, 30]\n",
    "for d in depth:\n",
    "    gb = GradientBoostingClassifier(random_state=42, max_depth=d).fit(X_train, y_train)\n",
    "    pred_train = gb.predict(X_train)\n",
    "    pred_test = gb.predict(X_test)\n",
    "    print('current depth {}'.format(d))\n",
    "    print(accuracy_score(y_train, pred_train))\n",
    "    print(accuracy_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk.stem.porter import *\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/meiyihe/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(stopwords.words('english')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"../data/renttherunway_final_data.json\"\n",
    "df = pd.read_json(file, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>body type</th>\n",
       "      <th>bust size</th>\n",
       "      <th>category</th>\n",
       "      <th>fit</th>\n",
       "      <th>height</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>rented for</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_summary</th>\n",
       "      <th>review_text</th>\n",
       "      <th>size</th>\n",
       "      <th>user_id</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.0</td>\n",
       "      <td>hourglass</td>\n",
       "      <td>34d</td>\n",
       "      <td>romper</td>\n",
       "      <td>fit</td>\n",
       "      <td>5' 8\"</td>\n",
       "      <td>2260466</td>\n",
       "      <td>10.0</td>\n",
       "      <td>vacation</td>\n",
       "      <td>April 20, 2016</td>\n",
       "      <td>So many compliments!</td>\n",
       "      <td>An adorable romper! Belt and zipper were a lit...</td>\n",
       "      <td>14</td>\n",
       "      <td>420272</td>\n",
       "      <td>137lbs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36.0</td>\n",
       "      <td>straight &amp; narrow</td>\n",
       "      <td>34b</td>\n",
       "      <td>gown</td>\n",
       "      <td>fit</td>\n",
       "      <td>5' 6\"</td>\n",
       "      <td>153475</td>\n",
       "      <td>10.0</td>\n",
       "      <td>other</td>\n",
       "      <td>June 18, 2013</td>\n",
       "      <td>I felt so glamourous!!!</td>\n",
       "      <td>I rented this dress for a photo shoot. The the...</td>\n",
       "      <td>12</td>\n",
       "      <td>273551</td>\n",
       "      <td>132lbs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sheath</td>\n",
       "      <td>fit</td>\n",
       "      <td>5' 4\"</td>\n",
       "      <td>1063761</td>\n",
       "      <td>10.0</td>\n",
       "      <td>party</td>\n",
       "      <td>December 14, 2015</td>\n",
       "      <td>It was a great time to celebrate the (almost) ...</td>\n",
       "      <td>This hugged in all the right places! It was a ...</td>\n",
       "      <td>4</td>\n",
       "      <td>360448</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.0</td>\n",
       "      <td>pear</td>\n",
       "      <td>34c</td>\n",
       "      <td>dress</td>\n",
       "      <td>fit</td>\n",
       "      <td>5' 5\"</td>\n",
       "      <td>126335</td>\n",
       "      <td>8.0</td>\n",
       "      <td>formal affair</td>\n",
       "      <td>February 12, 2014</td>\n",
       "      <td>Dress arrived on time and in perfect condition.</td>\n",
       "      <td>I rented this for my company's black tie award...</td>\n",
       "      <td>8</td>\n",
       "      <td>909926</td>\n",
       "      <td>135lbs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27.0</td>\n",
       "      <td>athletic</td>\n",
       "      <td>34b</td>\n",
       "      <td>gown</td>\n",
       "      <td>fit</td>\n",
       "      <td>5' 9\"</td>\n",
       "      <td>616682</td>\n",
       "      <td>10.0</td>\n",
       "      <td>wedding</td>\n",
       "      <td>September 26, 2016</td>\n",
       "      <td>Was in love with this dress !!!</td>\n",
       "      <td>I have always been petite in my upper body and...</td>\n",
       "      <td>12</td>\n",
       "      <td>151944</td>\n",
       "      <td>145lbs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age          body type bust size category  fit height  item_id  rating  \\\n",
       "0   28.0          hourglass       34d   romper  fit  5' 8\"  2260466    10.0   \n",
       "1   36.0  straight & narrow       34b     gown  fit  5' 6\"   153475    10.0   \n",
       "2  116.0                NaN       NaN   sheath  fit  5' 4\"  1063761    10.0   \n",
       "3   34.0               pear       34c    dress  fit  5' 5\"   126335     8.0   \n",
       "4   27.0           athletic       34b     gown  fit  5' 9\"   616682    10.0   \n",
       "\n",
       "      rented for         review_date  \\\n",
       "0       vacation      April 20, 2016   \n",
       "1          other       June 18, 2013   \n",
       "2          party   December 14, 2015   \n",
       "3  formal affair   February 12, 2014   \n",
       "4        wedding  September 26, 2016   \n",
       "\n",
       "                                      review_summary  \\\n",
       "0                               So many compliments!   \n",
       "1                            I felt so glamourous!!!   \n",
       "2  It was a great time to celebrate the (almost) ...   \n",
       "3   Dress arrived on time and in perfect condition.    \n",
       "4                    Was in love with this dress !!!   \n",
       "\n",
       "                                         review_text  size  user_id  weight  \n",
       "0  An adorable romper! Belt and zipper were a lit...    14   420272  137lbs  \n",
       "1  I rented this dress for a photo shoot. The the...    12   273551  132lbs  \n",
       "2  This hugged in all the right places! It was a ...     4   360448     NaN  \n",
       "3  I rented this for my company's black tie award...     8   909926  135lbs  \n",
       "4  I have always been petite in my upper body and...    12   151944  145lbs  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- map rented for to numerical value ---\n",
      "{'rented for': {'date': 1, 'everyday': 2, 'formal affair': 3, 'other': 4, 'party': 5, 'party: cocktail': 6, 'vacation': 7, 'wedding': 8, 'work': 9}}\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "\n",
    "# map 'rented for' to numerical value\n",
    "labels = df['rented for'].astype('category').cat.categories.tolist()\n",
    "replace_map = {'rented for' : {k: v for k,v in zip(labels,list(range(1,len(labels)+1)))}}\n",
    "print('--- map rented for to numerical value ---')\n",
    "print(replace_map)\n",
    "df.replace(replace_map, inplace=True)\n",
    "\n",
    "# strip punctuations\n",
    "review = []\n",
    "table = str.maketrans({key: None for key in string.punctuation})\n",
    "for idx, row in df.iterrows():\n",
    "    tmp = row['review_summary'] + \" \" +row['review_text']\n",
    "    tmp = tmp.translate(table)\n",
    "    review.append(tmp)\n",
    "    \n",
    "df_y = df['rented for'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 4, 3, 8, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'So many compliments An adorable romper Belt and zipper were a little hard to navigate in a full day of wearbathroom use but thats to be expected Wish it had pockets but other than that absolutely perfect I got a million compliments'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78189\n"
     ]
    }
   ],
   "source": [
    "# count how many unique words in the whole review pool\n",
    "punctuation = set(string.punctuation)\n",
    "r = ''.join([c.lower() for c in review if not c in punctuation])\n",
    "s = set(r.split( ))\n",
    "print(len(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try text mining + prediction here\n",
    "def getTopWords(data, num):\n",
    "    stemmer = PorterStemmer()\n",
    "    wordCount = defaultdict(int)\n",
    "    punctuation = set(string.punctuation)\n",
    "    r = ''.join([c.lower() for c in data if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        if w not in stopwords.words(\"english\"):\n",
    "            w = stemmer.stem(w)\n",
    "            wordCount[w] += 1\n",
    "    counts = [(wordCount[w], w) for w in wordCount]\n",
    "    counts.sort(reverse=True)\n",
    "    print(counts[:10])\n",
    "    wordList = [x[1] for x in counts[:num]]\n",
    "        \n",
    "    return wordList, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(261898, 'dress'), (97198, 'fit'), (71320, 'wear'), (69822, 'size'), (60281, 'love'), (53683, 'would'), (52871, 'great'), (51695, 'perfect'), (51342, 'wore'), (47691, 'compliment')]\n"
     ]
    }
   ],
   "source": [
    "wordList, counts = getTopWords(review, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "wholeList = [x[1] for x in counts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67597"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wholeList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return feature array of the text review\n",
    "def getFeature(topWords, text):\n",
    "    feat = [1]\n",
    "    rev = text.lower()\n",
    "    \n",
    "    for i in range(len(topWords)):\n",
    "        if topWords[i].lower() in rev:\n",
    "            feat.append(rev.count(topWords[i]))\n",
    "        else:\n",
    "            feat.append(0)\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct feature array, build df_X\n",
    "topWords = wholeList[:5000]\n",
    "df_X = []\n",
    "for i in review:\n",
    "    df_X.append(getFeature(topWords, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 2, 0, 1, 0, 0, 0, 0, 0, 1, 0]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X[0][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add tf-idf transformer\n",
    "tfidf = TfidfTransformer(sublinear_tf=True)\n",
    "df_X = tfidf.fit_transform(df_X)\n",
    "df_X = df_X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03150945, 0.        , 0.        , 0.06235305, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.06266221, 0.        ,\n",
       "       0.11456476, 0.        , 0.07609793, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.08307328, 0.        ])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X[0][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size=0.33, random_state=42 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6213713994392047\n",
      "0.581066534177949\n"
     ]
    }
   ],
   "source": [
    "# ridge classifier \n",
    "clf = linear_model.RidgeClassifier(fit_intercept=False)\n",
    "clf.fit(X_train, y_train)\n",
    "pred_train = clf.predict(X_train)\n",
    "print(accuracy_score(y_train, pred_train))\n",
    "\n",
    "pred_test = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192544, 15)\n",
      "(146381, 15)\n",
      "--- map body type to numerical value ---\n",
      "{'body type': {'apple': 1, 'athletic': 2, 'full bust': 3, 'hourglass': 4, 'pear': 5, 'petite': 6, 'straight & narrow': 7}}\n",
      "--- map category to numerical value ---\n",
      "{'category': {'ballgown': 1, 'blazer': 2, 'blouse': 3, 'blouson': 4, 'bomber': 5, 'buttondown': 6, 'caftan': 7, 'cami': 8, 'cape': 9, 'cardigan': 10, 'coat': 11, 'combo': 12, 'crewneck': 13, 'culotte': 14, 'culottes': 15, 'down': 16, 'dress': 17, 'duster': 18, 'for': 19, 'frock': 20, 'gown': 21, 'henley': 22, 'hoodie': 23, 'jacket': 24, 'jeans': 25, 'jogger': 26, 'jumpsuit': 27, 'kaftan': 28, 'kimono': 29, 'knit': 30, 'legging': 31, 'leggings': 32, 'maxi': 33, 'midi': 34, 'mini': 35, 'overalls': 36, 'overcoat': 37, 'pant': 38, 'pants': 39, 'parka': 40, 'peacoat': 41, 'poncho': 42, 'print': 43, 'pullover': 44, 'romper': 45, 'sheath': 46, 'shift': 47, 'shirt': 48, 'shirtdress': 49, 'skirt': 50, 'skirts': 51, 'skort': 52, 'suit': 53, 'sweater': 54, 'sweatershirt': 55, 'sweatpants': 56, 'sweatshirt': 57, 't-shirt': 58, 'tank': 59, 'tee': 60, 'tight': 61, 'top': 62, 'trench': 63, 'trouser': 64, 'trousers': 65, 'tunic': 66, 'turtleneck': 67, 'vest': 68}}\n",
      "--- map fit to numerical value ---\n",
      "{'fit': {'fit': 1, 'large': 2, 'small': 3}}\n",
      "--- map rented for to numerical value ---\n",
      "{'rented for': {'date': 1, 'everyday': 2, 'formal affair': 3, 'other': 4, 'party': 5, 'vacation': 6, 'wedding': 7, 'work': 8}}\n"
     ]
    }
   ],
   "source": [
    "# Pre-process Data \n",
    "\n",
    "# print original data shape\n",
    "print(df.shape)\n",
    "# drop NANs \n",
    "df = df.dropna()\n",
    "print(df.shape)\n",
    "# map 'body type' to numerical value\n",
    "labels = df['body type'].astype('category').cat.categories.tolist()\n",
    "replace_map = {'body type' : {k: v for k,v in zip(labels,list(range(1,len(labels)+1)))}}\n",
    "print('--- map body type to numerical value ---')\n",
    "print(replace_map)\n",
    "df.replace(replace_map, inplace=True)\n",
    "\n",
    "# remove the string after 'bust size'\n",
    "df['bust size'] = df['bust size'].str.extract('(\\d+)').astype(int)\n",
    "\n",
    "# parse height to usable numerical format\n",
    "def parse_height(ht):\n",
    "    ht_ = ht.split(\"' \")\n",
    "    ft_ = float(ht_[0])\n",
    "    in_ = float(ht_[1].replace(\"\\\"\",\"\"))\n",
    "    return (12*ft_) + in_\n",
    "df['height'] = df['height'].apply(lambda x:parse_height(x))\n",
    "\n",
    "# map 'category' to numerical value\n",
    "# ------ I think this part needs more cleansing -----\n",
    "labels = df['category'].astype('category').cat.categories.tolist()\n",
    "replace_map = {'category' : {k: v for k,v in zip(labels,list(range(1,len(labels)+1)))}}\n",
    "\n",
    "print('--- map category to numerical value ---')\n",
    "print(replace_map)\n",
    "df.replace(replace_map, inplace=True)\n",
    "\n",
    "\n",
    "# map 'fit' to numerical value\n",
    "labels = df['fit'].astype('category').cat.categories.tolist()\n",
    "replace_map = {'fit' : {k: v for k,v in zip(labels,list(range(1,len(labels)+1)))}}\n",
    "print('--- map fit to numerical value ---')\n",
    "print(replace_map)\n",
    "df.replace(replace_map, inplace=True)\n",
    "\n",
    "# remove strings after ':' in 'party: cocktail'\n",
    "df['rented for'] = df['rented for'].str.split(':').str[0]\n",
    "\n",
    "# remove lbs after 'weight'\n",
    "df['weight'] = df['weight'].str.extract('(\\d+)').astype(int)\n",
    "\n",
    "\n",
    "# map 'rented for' to numerical value\n",
    "labels = df['rented for'].astype('category').cat.categories.tolist()\n",
    "replace_map = {'rented for' : {k: v for k,v in zip(labels,list(range(1,len(labels)+1)))}}\n",
    "print('--- map rented for to numerical value ---')\n",
    "print(replace_map)\n",
    "df.replace(replace_map, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               float64\n",
       "body type           int64\n",
       "bust size           int64\n",
       "category            int64\n",
       "fit                 int64\n",
       "height            float64\n",
       "item_id             int64\n",
       "rating            float64\n",
       "rented for          int64\n",
       "review_date        object\n",
       "review_summary     object\n",
       "review_text        object\n",
       "size                int64\n",
       "user_id             int64\n",
       "weight              int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98075"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'rating'\n",
    "\n",
    "X_train = df_train.drop([label, 'review_date','review_summary', 'review_text'],axis=1)\n",
    "y_train = df_train[label]\n",
    "X_test = df_test.drop([label, 'review_date','review_summary', 'review_text'],axis=1)\n",
    "y_test = df_test[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>body type</th>\n",
       "      <th>bust size</th>\n",
       "      <th>category</th>\n",
       "      <th>fit</th>\n",
       "      <th>height</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rented for</th>\n",
       "      <th>size</th>\n",
       "      <th>user_id</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114785</th>\n",
       "      <td>37.0</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1851598</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>516231</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126377</th>\n",
       "      <td>32.0</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>64.0</td>\n",
       "      <td>174391</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>254634</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117721</th>\n",
       "      <td>37.0</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1316534</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>995881</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167358</th>\n",
       "      <td>35.0</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1055399</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>87081</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97435</th>\n",
       "      <td>28.0</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>64.0</td>\n",
       "      <td>242782</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>838084</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         age  body type  bust size  category  fit  height  item_id  \\\n",
       "114785  37.0          4         34        46    1    67.0  1851598   \n",
       "126377  32.0          4         32        17    1    64.0   174391   \n",
       "117721  37.0          2         34        17    1    65.0  1316534   \n",
       "167358  35.0          2         34        17    1    66.0  1055399   \n",
       "97435   28.0          4         36        21    1    64.0   242782   \n",
       "\n",
       "        rented for  size  user_id  weight  \n",
       "114785           5     8   516231     135  \n",
       "126377           3     1   254634     130  \n",
       "117721           8     8   995881     130  \n",
       "167358           8     8    87081     130  \n",
       "97435            3    24   838084     155  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import machine learning models\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(criterion = 'entropy', random_state = 42)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.596758166687368"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test = clf.predict(X_test)\n",
    "accuracy_score(y_test, pred_test)\n",
    "\n",
    "# probably needs text mining instead of using other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
