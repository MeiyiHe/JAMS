{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"./renttherunway_final_data.json\"\n",
    "df = pd.read_json(file,lines=True)\n",
    "df = df[['user_id','item_id','rating']]\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>420272</td>\n",
       "      <td>2260466</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>273551</td>\n",
       "      <td>153475</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>360448</td>\n",
       "      <td>1063761</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>909926</td>\n",
       "      <td>126335</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151944</td>\n",
       "      <td>616682</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating\n",
       "0   420272  2260466    10.0\n",
       "1   273551   153475    10.0\n",
       "2   360448  1063761    10.0\n",
       "3   909926   126335     8.0\n",
       "4   151944   616682    10.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = df.user_id.unique().shape[0]\n",
    "n_items = df.item_id.unique().shape[0]\n",
    "ratings = pd.DataFrame(np.zeros((n_users, n_items)), index = df.user_id.unique(), columns = list(df.item_id.unique()))\n",
    "for row in df.itertuples():\n",
    "    ratings.loc[row[1],row[2]] = row[3]\n",
    "ratings = np.array(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105508 users\n",
      "5850 items\n",
      "Sparsity: 0.03%\n"
     ]
    }
   ],
   "source": [
    "print (str(n_users) + ' users')\n",
    "print (str(n_items) + ' items')\n",
    "sparsity = float(len(ratings.nonzero()[0]))\n",
    "sparsity /= (ratings.shape[0] * ratings.shape[1])\n",
    "sparsity *= 100\n",
    "print ('Sparsity: {:4.2f}%'.format(sparsity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_count = 0\n",
    "one_count = 0\n",
    "two_count = 0\n",
    "three_count = 0\n",
    "for i in range(ratings.shape[0]):\n",
    "    if len(ratings[i, :].nonzero()[0]) > 9:\n",
    "        max_count+=1\n",
    "        \n",
    "    if len(ratings[i, :].nonzero()[0]) == 1:\n",
    "        one_count += 1\n",
    "        \n",
    "    if len(ratings[i, :].nonzero()[0]) == 2:\n",
    "        two_count += 1\n",
    "        \n",
    "    if len(ratings[i, :].nonzero()[0]) == 3:\n",
    "        three_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6808014558137772\n",
      "0.16936156499981045\n",
      "0.06513250180081132\n",
      "1388\n"
     ]
    }
   ],
   "source": [
    "print(one_count/n_users)\n",
    "print(two_count/n_users)\n",
    "print(three_count/n_users)\n",
    "print(max_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_users = []\n",
    "for i in range(ratings.shape[0]):\n",
    "    if len(ratings[i, :].nonzero()[0]) > 9:\n",
    "        test_users.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(ratings, test_users, s):\n",
    "    test = np.zeros(ratings.shape)\n",
    "    train = ratings.copy()\n",
    "    for user in test_users:\n",
    "        test_ratings = np.random.choice(ratings[user, :].nonzero()[0], size=s, replace=False)\n",
    "        train[user, test_ratings] = 0.\n",
    "        test[user, test_ratings] = ratings[user, test_ratings]\n",
    "        \n",
    "    # Test and training are truly disjoint\n",
    "    assert(np.all((train * test) == 0)) \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(ratings, test_users, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def get_mse(pred, actual):\n",
    "    # Ignore nonzero terms.\n",
    "    pred = pred[actual.nonzero()].flatten()\n",
    "    actual = actual[actual.nonzero()].flatten()\n",
    "    return mean_squared_error(pred, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExplicitMF():\n",
    "    def __init__(self, \n",
    "                 ratings,\n",
    "                 n_factors=40,\n",
    "                 learning='sgd',\n",
    "                 item_fact_reg=0.0, \n",
    "                 user_fact_reg=0.0,\n",
    "                 item_bias_reg=0.0,\n",
    "                 user_bias_reg=0.0,\n",
    "                 verbose=False):\n",
    "        \"\"\"\n",
    "        Train a matrix factorization model to predict empty \n",
    "        entries in a matrix. The terminology assumes a \n",
    "        ratings matrix which is ~ user x item\n",
    "        \n",
    "        Params\n",
    "        ======\n",
    "        ratings : (ndarray)\n",
    "            User x Item matrix with corresponding ratings\n",
    "        \n",
    "        n_factors : (int)\n",
    "            Number of latent factors to use in matrix \n",
    "            factorization model\n",
    "        learning : (str)\n",
    "            Method of optimization. Options include \n",
    "            'sgd' or 'als'.\n",
    "        \n",
    "        item_fact_reg : (float)\n",
    "            Regularization term for item latent factors\n",
    "        \n",
    "        user_fact_reg : (float)\n",
    "            Regularization term for user latent factors\n",
    "            \n",
    "        item_bias_reg : (float)\n",
    "            Regularization term for item biases\n",
    "        \n",
    "        user_bias_reg : (float)\n",
    "            Regularization term for user biases\n",
    "        \n",
    "        verbose : (bool)\n",
    "            Whether or not to printout training progress\n",
    "        \"\"\"\n",
    "        \n",
    "        self.ratings = ratings\n",
    "        self.n_users, self.n_items = ratings.shape\n",
    "        self.n_factors = n_factors\n",
    "        self.item_fact_reg = item_fact_reg\n",
    "        self.user_fact_reg = user_fact_reg\n",
    "        self.item_bias_reg = item_bias_reg\n",
    "        self.user_bias_reg = user_bias_reg\n",
    "        self.learning = learning\n",
    "        if self.learning == 'sgd':\n",
    "            self.sample_row, self.sample_col = self.ratings.nonzero()\n",
    "            self.n_samples = len(self.sample_row)\n",
    "        self._v = verbose\n",
    "\n",
    "    def als_step(self,\n",
    "                 latent_vectors,\n",
    "                 fixed_vecs,\n",
    "                 ratings,\n",
    "                 _lambda,\n",
    "                 type='user'):\n",
    "        \"\"\"\n",
    "        One of the two ALS steps. Solve for the latent vectors\n",
    "        specified by type.\n",
    "        \"\"\"\n",
    "        if type == 'user':\n",
    "            # Precompute\n",
    "            YTY = fixed_vecs.T.dot(fixed_vecs)\n",
    "            lambdaI = np.eye(YTY.shape[0]) * _lambda\n",
    "\n",
    "            for u in range(latent_vectors.shape[0]):\n",
    "                latent_vectors[u, :] = solve((YTY + lambdaI), \n",
    "                                             ratings[u, :].dot(fixed_vecs))\n",
    "        elif type == 'item':\n",
    "            # Precompute\n",
    "            XTX = fixed_vecs.T.dot(fixed_vecs)\n",
    "            lambdaI = np.eye(XTX.shape[0]) * _lambda\n",
    "            \n",
    "            for i in range(latent_vectors.shape[0]):\n",
    "                latent_vectors[i, :] = solve((XTX + lambdaI), \n",
    "                                             ratings[:, i].T.dot(fixed_vecs))\n",
    "        return latent_vectors\n",
    "\n",
    "    def train(self, n_iter=10, learning_rate=0.1):\n",
    "        \"\"\" Train model for n_iter iterations from scratch.\"\"\"\n",
    "        # initialize latent vectors        \n",
    "        self.user_vecs = np.random.normal(scale=1./self.n_factors,size=(self.n_users, self.n_factors))\n",
    "        self.item_vecs = np.random.normal(scale=1./self.n_factors,size=(self.n_items, self.n_factors))\n",
    "        \n",
    "        if self.learning == 'als':\n",
    "            self.partial_train(n_iter)\n",
    "        elif self.learning == 'sgd':\n",
    "            self.learning_rate = learning_rate\n",
    "            self.user_bias = np.zeros(self.n_users)\n",
    "            self.item_bias = np.zeros(self.n_items)\n",
    "            self.global_bias = np.mean(self.ratings[np.where(self.ratings != 0)])\n",
    "            self.partial_train(n_iter)\n",
    "    \n",
    "    \n",
    "    def partial_train(self, n_iter):\n",
    "        \"\"\" \n",
    "        Train model for n_iter iterations. Can be \n",
    "        called multiple times for further training.\n",
    "        \"\"\"\n",
    "        ctr = 1\n",
    "        while ctr <= n_iter:\n",
    "            if ctr % 10 == 0 and self._v:\n",
    "                print ('\\tcurrent iteration: {}'.format(ctr))\n",
    "            if self.learning == 'als':\n",
    "                self.user_vecs = self.als_step(self.user_vecs, \n",
    "                                               self.item_vecs, \n",
    "                                               self.ratings, \n",
    "                                               self.user_fact_reg, \n",
    "                                               type='user')\n",
    "                self.item_vecs = self.als_step(self.item_vecs, \n",
    "                                               self.user_vecs, \n",
    "                                               self.ratings, \n",
    "                                               self.item_fact_reg, \n",
    "                                               type='item')\n",
    "            elif self.learning == 'sgd':\n",
    "                self.training_indices = np.arange(self.n_samples)\n",
    "                np.random.shuffle(self.training_indices)\n",
    "                self.sgd()\n",
    "            ctr += 1\n",
    "\n",
    "    def sgd(self):\n",
    "        for idx in self.training_indices:\n",
    "#             print('idx',idx)\n",
    "            u = self.sample_row[idx]\n",
    "#             print('u',u)\n",
    "            i = self.sample_col[idx]\n",
    "#             print('i',i)\n",
    "            prediction = self.predict(u, i)\n",
    "            e = self.ratings[u,i] - prediction # error \n",
    "#             print('prediction',prediction)\n",
    "            \n",
    "            # Update biases\n",
    "            self.user_bias[u] += self.learning_rate * (e - self.user_bias_reg * self.user_bias[u])\n",
    "#             print('self.user_bias[u]',self.user_bias[u])\n",
    "            self.item_bias[i] += self.learning_rate * (e - self.item_bias_reg * self.item_bias[i])\n",
    "#             print('self.item_bias[i]',self.item_bias[i])\n",
    "            \n",
    "            #Update latent factors\n",
    "            self.user_vecs[u, :] += self.learning_rate * (e * self.item_vecs[i, :] - self.user_fact_reg * self.user_vecs[u,:])\n",
    "            self.item_vecs[i, :] += self.learning_rate * (e * self.user_vecs[u, :] - self.item_fact_reg * self.item_vecs[i,:])\n",
    "    \n",
    "    def predict(self, u, i):\n",
    "        \"\"\" Single user and item prediction.\"\"\"\n",
    "        if self.learning == 'als':\n",
    "            return self.user_vecs[u, :].dot(self.item_vecs[i, :].T)\n",
    "        elif self.learning == 'sgd':\n",
    "            prediction = self.global_bias + self.user_bias[u] + self.item_bias[i]\n",
    "#             print('self.user_bias[u]_pre',self.user_bias[u])\n",
    "#             print('self.item_bias[i]_pre',self.item_bias[i])\n",
    "            prediction += self.user_vecs[u, :].dot(self.item_vecs[i, :].T)\n",
    "            return prediction\n",
    "    \n",
    "    def predict_all(self):\n",
    "        \"\"\" Predict ratings for every user and item.\"\"\"\n",
    "        predictions = np.zeros((self.user_vecs.shape[0], \n",
    "                                self.item_vecs.shape[0]))\n",
    "        r = self.user_vecs.shape[0]\n",
    "        c = self.item_vecs.shape[0]\n",
    "        global_bias = np.repeat(self.global_bias, r*c).reshape(r,c)\n",
    "        user_bias = np.repeat(self.user_bias, c, axis=0).reshape(r,c)\n",
    "        print(user_bias)\n",
    "        item_bias = np.repeat(self.item_bias, r, axis=0).reshape(c,r).T\n",
    "        print(item_bias)\n",
    "        predictions = np.matmul(self.user_vecs,self.item_vecs.T)+global_bias+user_bias+item_bias\n",
    "#         for u in range(self.user_vecs.shape[0]):\n",
    "#             for i in range(self.item_vecs.shape[0]):\n",
    "#                 predictions[u, i] = self.predict(u, i)\n",
    "        return predictions\n",
    "    \n",
    "    def calculate_learning_curve(self, iter_array, test, learning_rate=0.1):\n",
    "        \"\"\"\n",
    "        Keep track of MSE as a function of training iterations.\n",
    "        \n",
    "        Params\n",
    "        ======\n",
    "        iter_array : (list)\n",
    "            List of numbers of iterations to train for each step of \n",
    "            the learning curve. e.g. [1, 5, 10, 20]\n",
    "        test : (2D ndarray)\n",
    "            Testing dataset (assumed to be user x item).\n",
    "        \n",
    "        The function creates two new class attributes:\n",
    "        \n",
    "        train_mse : (list)\n",
    "            Training data MSE values for each value of iter_array\n",
    "        test_mse : (list)\n",
    "            Test data MSE values for each value of iter_array\n",
    "        \"\"\"\n",
    "        iter_array.sort()\n",
    "        self.train_mse =[]\n",
    "        self.test_mse = []\n",
    "        iter_diff = 0\n",
    "        for (i, n_iter) in enumerate(iter_array):\n",
    "            if self._v:\n",
    "                print ('Iteration: {}'.format(n_iter))\n",
    "            if i == 0:\n",
    "                self.train(n_iter - iter_diff, learning_rate)\n",
    "            else:\n",
    "                self.partial_train(n_iter - iter_diff)\n",
    "\n",
    "            predictions = self.predict_all()\n",
    "#             print(predictions)\n",
    "\n",
    "            self.train_mse += [get_mse(predictions, self.ratings)]\n",
    "            self.test_mse += [get_mse(predictions, test)]\n",
    "            if self._v:\n",
    "                print ('Train mse: ' + str(self.train_mse[-1]))\n",
    "                print ('Test mse: ' + str(self.test_mse[-1]))\n",
    "            iter_diff = n_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\n",
      "[[-0.08262239 -0.08262239 -0.08262239 ... -0.08262239 -0.08262239\n",
      "  -0.08262239]\n",
      " [ 0.00843556  0.00843556  0.00843556 ...  0.00843556  0.00843556\n",
      "   0.00843556]\n",
      " [ 0.00739227  0.00739227  0.00739227 ...  0.00739227  0.00739227\n",
      "   0.00739227]\n",
      " ...\n",
      " [-0.00736123 -0.00736123 -0.00736123 ... -0.00736123 -0.00736123\n",
      "  -0.00736123]\n",
      " [ 0.01424442  0.01424442  0.01424442 ...  0.01424442  0.01424442\n",
      "   0.01424442]\n",
      " [ 0.0051673   0.0051673   0.0051673  ...  0.0051673   0.0051673\n",
      "   0.0051673 ]]\n",
      "[[-0.19296303  0.03284214  0.14365255 ...  0.         -0.04958717\n",
      "  -0.01021779]\n",
      " [-0.19296303  0.03284214  0.14365255 ...  0.         -0.04958717\n",
      "  -0.01021779]\n",
      " [-0.19296303  0.03284214  0.14365255 ...  0.         -0.04958717\n",
      "  -0.01021779]\n",
      " ...\n",
      " [-0.19296303  0.03284214  0.14365255 ...  0.         -0.04958717\n",
      "  -0.01021779]\n",
      " [-0.19296303  0.03284214  0.14365255 ...  0.         -0.04958717\n",
      "  -0.01021779]\n",
      " [-0.19296303  0.03284214  0.14365255 ...  0.         -0.04958717\n",
      "  -0.01021779]]\n",
      "Train mse: 1.8854302991841316\n",
      "Test mse: 2.1769377793533637\n",
      "Iteration: 2\n",
      "[[-0.15378394 -0.15378394 -0.15378394 ... -0.15378394 -0.15378394\n",
      "  -0.15378394]\n",
      " [ 0.01727899  0.01727899  0.01727899 ...  0.01727899  0.01727899\n",
      "   0.01727899]\n",
      " [ 0.01420055  0.01420055  0.01420055 ...  0.01420055  0.01420055\n",
      "   0.01420055]\n",
      " ...\n",
      " [-0.0137048  -0.0137048  -0.0137048  ... -0.0137048  -0.0137048\n",
      "  -0.0137048 ]\n",
      " [ 0.02595052  0.02595052  0.02595052 ...  0.02595052  0.02595052\n",
      "   0.02595052]\n",
      " [ 0.00865204  0.00865204  0.00865204 ...  0.00865204  0.00865204\n",
      "   0.00865204]]\n",
      "[[-0.3121852   0.04856364  0.23722563 ...  0.         -0.09814224\n",
      "  -0.02014617]\n",
      " [-0.3121852   0.04856364  0.23722563 ...  0.         -0.09814224\n",
      "  -0.02014617]\n",
      " [-0.3121852   0.04856364  0.23722563 ...  0.         -0.09814224\n",
      "  -0.02014617]\n",
      " ...\n",
      " [-0.3121852   0.04856364  0.23722563 ...  0.         -0.09814224\n",
      "  -0.02014617]\n",
      " [-0.3121852   0.04856364  0.23722563 ...  0.         -0.09814224\n",
      "  -0.02014617]\n",
      " [-0.3121852   0.04856364  0.23722563 ...  0.         -0.09814224\n",
      "  -0.02014617]]\n",
      "Train mse: 1.800150791336253\n",
      "Test mse: 2.124023238127931\n"
     ]
    }
   ],
   "source": [
    "MF_SGD = ExplicitMF(train, 4, learning='sgd', verbose=True)\n",
    "iter_array = [1, 2]\n",
    "MF_SGD.calculate_learning_curve(iter_array, test, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.repeat(a, 3, axis = 0).reshape(5,3).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
